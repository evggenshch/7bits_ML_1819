{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашняя работа 9. Деревья решений. (32 балла)\n",
    "\n",
    "1. Скачайте этот ноутбук к себе.\n",
    "2. Заполните пропущенные ячейки, отвечая на заданные вопросы. Там должен быть код! (если не сказано обратное)\n",
    "3. Сохраните результат в своём гитхаб репозитории.\n",
    "\n",
    "## Полезная литература\n",
    "\n",
    "- [Habrahabr: ODS деревья решений](https://habrahabr.ru/company/ods/blog/322534/#derevo-resheniy)\n",
    "- [ВМК МГУ семинары по решающим деревьям](https://github.com/esokolov/ml-course-msu/blob/master/ML16/lecture-notes/Sem04_trees.pdf)\n",
    "- [Sklearn Decision Trees](http://scikit-learn.org/stable/modules/tree.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Сравнение моделей деревьев\n",
    "\n",
    "В этом блоке вы сравните разные конфигурации композиций деревьев:\n",
    "- DecisionTree\n",
    "- Bagging\n",
    "- Bagging с другими настройками подбора признаков для разбиения\n",
    "- RandomForest\n",
    "\n",
    "Будем использовать [датасет с винишком](https://archive.ics.uci.edu/ml/datasets/wine+quality) - это задача то ли классификации то ли регресси - нужно предсказывать качество вина. Будем думать что это классификация.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/en/thumb/7/7c/Lulz_Security.svg/300px-Lulz_Security.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Чтение данных (1 балла)\n",
    "\n",
    "Данные лежат как обычно в `'../../data/winequality-red.csv.gz'`.\n",
    "\n",
    "- Прочитайте их с помощью pandas\n",
    "- нарисуйте countplot целевого признака `quality`.\n",
    "- Что вы думаете по поводу количества представителей каждого класса.\n",
    "- Разбейте данные на X и y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult.csv.gz\r\n",
      "data\r\n",
      "Homework_1.ipynb\r\n",
      "titanic_train.csv\r\n",
      "week01_homework_01_homework.ipynb\r\n",
      "week04_homework_04-01-clustering-homework.ipynb\r\n",
      "week04_workshop_04-01-clustering-workshop.ipynb\r\n",
      "week05_workshop_05-01-clustering-workshop.ipynb\r\n",
      "week06_workshop_06-01-linear-regression-homework.ipynb\r\n",
      "week07_workshop_07-01-classification.ipynb\r\n",
      "week08_workshop_08-01-text-classification-bayes_workshop.ipynb\r\n",
      "week09_09-02-decision-trees-workshop.ipynb\r\n",
      "week10_10-02-ensembles-workshop.ipynb\r\n",
      "week2_homework_02-01-homework-numpy.ipynb\r\n",
      "week2_homework_02-02-homework-pandas.ipynb\r\n",
      "week2_workshop_02-01-workshop-numpy.ipynb\r\n",
      "week2_workshop_02-02-workshop-pandas.ipynb\r\n",
      "week3_homework_03-01-visualisation-homework.ipynb\r\n",
      "week3_workshop_03-01-visualisation-workshop.ipynb\r\n",
      "Workshop_1.ipynb\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ls\n",
    "\n",
    "df = pd.read_csv('data/data_winequality-red.csv.gz', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f38d96c63c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = df['quality'], data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Сравнение моделей (4 балла)\n",
    "\n",
    "Задача классификации. Все признаки уже числовые. Значит можно пробовать просто все модели и выбрать лучшую. Так и поступим, сделайте кросс валидацию на 5 фолдах, используя `sklearn.model_selection.KFold` как аргумент у `cross_val_score`. Метрика качества будет `accuracy`.\n",
    "\n",
    "Алгоритмы для тестирования:\n",
    "- KNeighborsClassifier с 10 соседями\n",
    "- KNeighborsClassifier с 10 соседями и масштабированием StandartScaler\n",
    "- RidgeClassifier\n",
    "- DecisionTreeClassifier \n",
    "- BaggingClassifier c 100 деревьев\n",
    "- BaggingClassifier с 100 деревьев и каждое дерево обучается только по половине случайно выбранных признаков (см аргументы)\n",
    "- RandomForestClassifier c 100 деревьев\n",
    "\n",
    "Выведите среднее значение метрики качества для каждого из классификаторов. \n",
    "\n",
    "**hint**: каждый следующий алгоритм, будет показывать качество лучше, чем предыдущий. Если у вас не так - то что-то вы делаете неправильно. Везде зафиксируйте random_state=42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(10): 0.44902821316614416\n",
      "KNeighborsClassifier(10) with StandartScaler: 0.5490889498432602\n",
      "RidgeClassifier: 0.575384012539185\n",
      "DecisionTreeClassifier: 0.45154584639498435\n",
      "BaggingClassifier: 0.5703585423197493\n",
      "BaggingClassifier(half features): 0.5691281347962381\n",
      "RandomForestClassifier: 0.5428663793103448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evggenshch/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/evggenshch/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/evggenshch/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/evggenshch/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/evggenshch/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "reg = KNeighborsClassifier(n_neighbors=10)\n",
    "print(\"KNeighborsClassifier(10):\",cross_val_score(reg, X, y, scoring='accuracy', cv=KFold(n_splits = 5, random_state=42)).mean())\n",
    "scaler = StandardScaler()\n",
    "X_2 = X \n",
    "X_2 = scaler.fit_transform(X_2, y)\n",
    "reg = KNeighborsClassifier(n_neighbors=10)\n",
    "print(\"KNeighborsClassifier(10) with StandartScaler:\",cross_val_score(reg, X_2, y, scoring='accuracy', cv=KFold(n_splits = 5, random_state=42)).mean())\n",
    "reg = RidgeClassifier(random_state=42)\n",
    "print(\"RidgeClassifier:\",cross_val_score(reg, X, y, scoring='accuracy', cv=KFold(n_splits = 5, random_state=42)).mean())\n",
    "reg_tree = DecisionTreeClassifier(random_state=42)\n",
    "print(\"DecisionTreeClassifier:\",cross_val_score(reg_tree, X, y, scoring='accuracy', cv=KFold(n_splits = 5, random_state=42)).mean())\n",
    "reg = BaggingClassifier(base_estimator = reg_tree, n_estimators=100, random_state = 42)\n",
    "print(\"BaggingClassifier:\",cross_val_score(reg, X, y, scoring='accuracy', cv=KFold(n_splits = 5, random_state=42)).mean())\n",
    "reg = BaggingClassifier(base_estimator = reg_tree, n_estimators=100, max_features=0.5, random_state = 42)\n",
    "print(\"BaggingClassifier(half features):\",cross_val_score(reg, X, y, scoring='accuracy', cv=KFold(n_splits = 5, random_state=42)).mean())\n",
    "reg = RandomForestClassifier(random_state = 42)\n",
    "print(\"RandomForestClassifier:\",cross_val_score(reg, X, y, scoring='accuracy', cv=KFold(n_splits = 5, random_state=42)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Расуждения (8 баллов)\n",
    "\n",
    "Ответьте на вопросы развернуто, можете полистать литературу:\n",
    "\n",
    "- почему наблюдается значимая разница в качестве у KNeighborsClassifier с масштабированием и без\n",
    "- почему масштабирование не важно для деревьев решений\n",
    "- почему бэггинг на половине признаков для каждого дерева дал качество предсказания больше, чем на всех? (а он дал!)\n",
    "- у какой модели наибольшей отклонение от среднего качества предсказаний? А почему??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку KNeighborsClassifier линейная модель, масштабирование позволяет уравновесить признаки.\n",
    "Деревья решения рассматривают признаки по отдельности, поэтому для них масштабирование играет меньшую роль."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Переобучение и Ко\n",
    "\n",
    "В последнем задании вы уже заметили, что случайный лес может вести себя немного нестабильно. В этом задании мы возьмем опять датасет MNIST(простите) и будем его решать деревьями. Почему мы взяли его? Потому что в нем фактически много разных признаков (значения пикселей в пространстве), а деревья строятся делая разбиения по признакам. Обычно на эти разбиения не обращают внимание, так как главное что тюнят - это глубина дереьвев, количество деревьев, а кучу других параметров обходят стороной, так как они \"неясные\". Попробуем прояснить их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Загрузка датасета (1 балл)\n",
    "\n",
    "Загрузите датасет с помощью функции `sklearn.datasets.load_digits`. В нем будут 64px картинки в векторной форме.\n",
    "\n",
    "Нарисуйте первые 10 цифр в одной ячейке, чтобы было красиво."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape) \n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Перебор классификаторов (3 балла)\n",
    "\n",
    "В этом задании вам снова придется перебрать несколько классификаторов, но теперь мы обратим внимание на другие гиперпараметры и их влияние на качество классификации, кстати опять `accuracy`.\n",
    "\n",
    "Сделайте кроссвалидацию на 10 фолдах, указав `cv=10` для следующих классификаторов:\n",
    "\n",
    "- DecisionTreeClassifier с параметрами по-умолчанию\n",
    "- BaggingClassifier с 100 деревьвев\n",
    "- BaggingClassifier с 100 деревьев, НО с ограничением на максимальное количество признаков, участвующих при обучении каждого из деревьев в $\\sqrt{N}$, где $N$ - это число признаков.\n",
    "- BaggingClassifier с 100 деревьев, НО с ограничением на количество признаков участвующих в разбиении для каждого из деревьев в $\\sqrt{N}$, где $N$ - это число признаков. Это отличается от предыдущей модели тем, где ограничивается `max_features`. Читайте документацию :trollface:\n",
    "- обычный случайный лес со 100 деревьями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = DecisionTreeClassifier()\n",
    "print(\"KNeighborsClassifier(10):\",cross_val_score(reg, X, y, scoring='accuracy', cv=KFold(n_splits = 10, random_state=42)))\n",
    "reg2 = BaggingClassifier()\n",
    "reg_tree2 = DecisionTreeClassifier(random_state=42)\n",
    "reg2 = BaggingClassifier(base_estimator = reg_tree, n_estimators=100, random_state = 42)\n",
    "print(\"BaggingClassifier:\",cross_val_score(reg2, X, y, scoring='accuracy', cv=KFold(n_splits = 10, random_state=42)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 В чём разница? (3 балла)\n",
    "\n",
    "Ответье на вопрос: \n",
    "\n",
    "Странно то как? Почему ограничение на количество признаков в разбиении дерева и ограничение в количестве признаков для построения каждого дерева в BaggingClasifier дало СОВСЕМ разный результат в качестве предсказания? В чем магия?\n",
    "\n",
    "![](https://i.ytimg.com/vi/_5GWMIAHc08/hqdefault.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Количество деревьев (2 балла)\n",
    "\n",
    "Сделайте перебор количества деревьев для `RandomForestClassifier`. Сохраните качества кросс валидации на 10 фолдах для `[1,5,10,15,50,100,150,200,300]` количества деревьев. Нарисуйте график, где по оси x - количество деревьев, а по оси y - качество. При каком количестве деревьев получается самое хорошее качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Количество признаков  (2 балла)\n",
    "\n",
    "Переберите теперь максимальное количество признаков для `RandomForestClassifier` на 100 деревьях, от 1 до 64 с шагом 5. Постройте график качества по кроссвалидации на 10 фолдах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Вопросы по RandomForest (8 баллов)\n",
    "\n",
    "Ответьте на вопросы:\n",
    "\n",
    "- Что происходит с ростом числа деревьев у случайного леса. Можно ли просто всегда брать 5000 деревьев и быть счастливым?\n",
    "- Как зависит качество предсказания в дереве в зависимости от max_features?\n",
    "- Почему качество зависит от max_features?\n",
    "- Как глубина деревьев влияет на качество случайного леса?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://habrastorage.org/web/ad8/366/a44/ad8366a4469346c6b2e1306495b05d1a.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
